# ğ€ğ³ğ®ğ«ğ ğ„ğ§ğ-ğ­ğ¨-ğ„ğ§ğ ğƒğšğ­ğš ğğ¢ğ©ğğ¥ğ¢ğ§ğ

In this project, I've shared my work around implementing an end-to-end data engineering pipeline using Microsoft Azure Services. The pipeline has 7 steps:
1. Raw data: provided on GitHub
2. Azure Data Factory(ADF): for pipeline orchestration
3. Azure Data Lake Storage(ADL): to store raw data
4. Databricks: used for data transformation by PySpark
5. Azure Data Lake Storage(ADL): to store transformed data
6. Azure Synapse Analytics: for data warehousing purposes
7. Power BI: for data visualization
