# 𝐀𝐳𝐮𝐫𝐞 𝐄𝐧𝐝-𝐭𝐨-𝐄𝐧𝐝 𝐃𝐚𝐭𝐚 𝐏𝐢𝐩𝐞𝐥𝐢𝐧𝐞

In this project, I've shared my work around implementing an end-to-end data engineering pipeline using Microsoft Azure Services. The pipeline has 7 steps:
1. Raw data: provided on GitHub
2. Azure Data Factory(ADF): for pipeline orchestration
3. Azure Data Lake Storage(ADL): to store raw data
4. Databricks: used for data transformation by PySpark
5. Azure Data Lake Storage(ADL): to store transformed data
6. Azure Synapse Analytics: for data warehousing purposes
7. Power BI: for data visualization
